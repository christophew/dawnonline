#summary The brain of the agents.

= Introduction =

The brain consists of a collection of neural networks:
 * a nr of behaviour neural networks
 * a behaviour controller who decides which behaviour is active


= Brain design =

https://docs.google.com/drawings/d/1fHKhwBHa2Fk8tQwUc3xjB0KFyz63aYjOf399IMKT9Qg/pub?w=739&h=294&nonsense=dummy.jpg


The behaviour mode networks are all have an identical topology.
The behaviour controller slightly differences: it has the same amount of input nodes, but 3 specific output nodes, each favouring a different behaviour.

= Neural network =

The neural network used is a 3 layer feedforward network with a large number of reinforcement nodes (see: http://en.wikipedia.org/wiki/Artificial_neural_network#Reinforcement_learning).

== Input layer ==

In the current setup, each agent has 3 eye sensors, 1 nose, 1 bumper, 3 monitors (health, stamina & resources gathered) and 2 random generators.

The eye sensors are configured to look for:
 * Prey: do I see something I can kill?
 * Resources: do I see something I can gather?
 * Walls: do I see a wall?
 * Family: do I see a member of my family?
 * SpawnPoint: do I see my SpawnPoint?

This results into 25 input nodes (and an equal amount of reinforcement nodes).

== Hidden layer ==

The hidden layer consists of an equal amount of nodes as the input layer (= 2x the input nodes).

== Output layer ==

We only have 2 ouput nodes:
 * Turn
 * Thrust

But, the output layer also contains the 25 reinforcement output nodes.

= 27 output nodes





